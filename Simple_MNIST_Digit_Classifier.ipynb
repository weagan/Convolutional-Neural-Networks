{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlPntQfjVhbGgwiPQmlLnY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weagan/Convolutional-Neural-Networks/blob/main/Simple_MNIST_Digit_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9d28948",
        "outputId": "eb4630aa-76f0-4c3c-89a9-bafaac0ad298"
      },
      "source": [
        "!git clone https://github.com/TheIndependentCode/Neural-Network"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Neural-Network'...\n",
            "remote: Enumerating objects: 50, done.\u001b[K\n",
            "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 50 (delta 17), reused 14 (delta 14), pack-reused 21 (from 1)\u001b[K\n",
            "Receiving objects: 100% (50/50), 9.82 KiB | 3.27 MiB/s, done.\n",
            "Resolving deltas: 100% (23/23), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f8a67e9",
        "outputId": "ce6b0859-f988-43af-d2a5-72c620fb9377"
      },
      "source": [
        "with open('/content/Neural-Network/mnist.py', 'r') as f:\n",
        "    mnist_content = f.read()\n",
        "print(mnist_content)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import numpy as np\n",
            "from keras.datasets import mnist\n",
            "from keras.utils import np_utils\n",
            "\n",
            "from dense import Dense\n",
            "from activations import Tanh\n",
            "from losses import mse, mse_prime\n",
            "from network import train, predict\n",
            "\n",
            "\n",
            "def preprocess_data(x, y, limit):\n",
            "    # reshape and normalize input data\n",
            "    x = x.reshape(x.shape[0], 28 * 28, 1)\n",
            "    x = x.astype(\"float32\") / 255\n",
            "    # encode output which is a number in range [0,9] into a vector of size 10\n",
            "    # e.g. number 3 will become [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "    y = np_utils.to_categorical(y)\n",
            "    y = y.reshape(y.shape[0], 10, 1)\n",
            "    return x[:limit], y[:limit]\n",
            "\n",
            "\n",
            "# load MNIST from server\n",
            "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
            "x_train, y_train = preprocess_data(x_train, y_train, 1000)\n",
            "x_test, y_test = preprocess_data(x_test, y_test, 20)\n",
            "\n",
            "# neural network\n",
            "network = [\n",
            "    Dense(28 * 28, 40),\n",
            "    Tanh(),\n",
            "    Dense(40, 10),\n",
            "    Tanh()\n",
            "]\n",
            "\n",
            "# train\n",
            "train(network, mse, mse_prime, x_train, y_train, epochs=100, learning_rate=0.1)\n",
            "\n",
            "# test\n",
            "for x, y in zip(x_test, y_test):\n",
            "    output = predict(network, x)\n",
            "    print('pred:', np.argmax(output), '\\ttrue:', np.argmax(y))\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a312177e"
      },
      "source": [
        "### `mnist.py` converted to notebook cells\n",
        "\n",
        "Below are the contents of `mnist.py` broken down into logical code cells."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c29fefa"
      },
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/Neural-Network/')\n",
        "\n",
        "from dense import Dense\n",
        "from activations import Tanh\n",
        "from losses import mse, mse_prime\n",
        "from network import train, predict"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44858be7"
      },
      "source": [
        "def preprocess_data(x, y, limit):\n",
        "    # reshape and normalize input data\n",
        "    x = x.reshape(x.shape[0], 28 * 28, 1)\n",
        "    x = x.astype(\"float32\") / 255\n",
        "    # encode output which is a number in range [0,9] into a vector of size 10\n",
        "    # e.g. number 3 will become [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
        "    y = to_categorical(y)\n",
        "    y = y.reshape(y.shape[0], 10, 1)\n",
        "    return x[:limit], y[:limit]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7753cd6b",
        "outputId": "80dd117a-1bce-4437-e327-2310f80e157b"
      },
      "source": [
        "# load MNIST from server\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, y_train = preprocess_data(x_train, y_train, 1000)\n",
        "x_test, y_test = preprocess_data(x_test, y_test, 20)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bdae597",
        "outputId": "5b661de3-9548-434a-aa86-eb0bb900ae4e"
      },
      "source": [
        "print('First training image (x_train[0]):')\n",
        "print(x_train[0])\n",
        "print('\\nFirst training label (y_train[0]):')\n",
        "print(y_train[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First training image (x_train[0]):\n",
            "[[0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.01176471]\n",
            " [0.07058824]\n",
            " [0.07058824]\n",
            " [0.07058824]\n",
            " [0.49411765]\n",
            " [0.53333336]\n",
            " [0.6862745 ]\n",
            " [0.10196079]\n",
            " [0.6509804 ]\n",
            " [1.        ]\n",
            " [0.96862745]\n",
            " [0.49803922]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.11764706]\n",
            " [0.14117648]\n",
            " [0.36862746]\n",
            " [0.6039216 ]\n",
            " [0.6666667 ]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.88235295]\n",
            " [0.6745098 ]\n",
            " [0.99215686]\n",
            " [0.9490196 ]\n",
            " [0.7647059 ]\n",
            " [0.2509804 ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.19215687]\n",
            " [0.93333334]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.9843137 ]\n",
            " [0.3647059 ]\n",
            " [0.32156864]\n",
            " [0.32156864]\n",
            " [0.21960784]\n",
            " [0.15294118]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.07058824]\n",
            " [0.85882354]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.7764706 ]\n",
            " [0.7137255 ]\n",
            " [0.96862745]\n",
            " [0.94509804]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.3137255 ]\n",
            " [0.6117647 ]\n",
            " [0.41960785]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.8039216 ]\n",
            " [0.04313726]\n",
            " [0.        ]\n",
            " [0.16862746]\n",
            " [0.6039216 ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.05490196]\n",
            " [0.00392157]\n",
            " [0.6039216 ]\n",
            " [0.99215686]\n",
            " [0.3529412 ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.54509807]\n",
            " [0.99215686]\n",
            " [0.74509805]\n",
            " [0.00784314]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.04313726]\n",
            " [0.74509805]\n",
            " [0.99215686]\n",
            " [0.27450982]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.13725491]\n",
            " [0.94509804]\n",
            " [0.88235295]\n",
            " [0.627451  ]\n",
            " [0.42352942]\n",
            " [0.00392157]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.31764707]\n",
            " [0.9411765 ]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.46666667]\n",
            " [0.09803922]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.1764706 ]\n",
            " [0.7294118 ]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.5882353 ]\n",
            " [0.10588235]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.0627451 ]\n",
            " [0.3647059 ]\n",
            " [0.9882353 ]\n",
            " [0.99215686]\n",
            " [0.73333335]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.9764706 ]\n",
            " [0.99215686]\n",
            " [0.9764706 ]\n",
            " [0.2509804 ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.18039216]\n",
            " [0.50980395]\n",
            " [0.7176471 ]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.8117647 ]\n",
            " [0.00784314]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.15294118]\n",
            " [0.5803922 ]\n",
            " [0.8980392 ]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.98039216]\n",
            " [0.7137255 ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.09411765]\n",
            " [0.44705883]\n",
            " [0.8666667 ]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.7882353 ]\n",
            " [0.30588236]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.09019608]\n",
            " [0.25882354]\n",
            " [0.8352941 ]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.7764706 ]\n",
            " [0.31764707]\n",
            " [0.00784314]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.07058824]\n",
            " [0.67058825]\n",
            " [0.85882354]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.7647059 ]\n",
            " [0.3137255 ]\n",
            " [0.03529412]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.21568628]\n",
            " [0.6745098 ]\n",
            " [0.8862745 ]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.95686275]\n",
            " [0.52156866]\n",
            " [0.04313726]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.53333336]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.99215686]\n",
            " [0.83137256]\n",
            " [0.5294118 ]\n",
            " [0.5176471 ]\n",
            " [0.0627451 ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]]\n",
            "\n",
            "First training label (y_train[0]):\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54c2662e",
        "outputId": "9f4c23e0-81b3-4740-d90c-9f091980b942"
      },
      "source": [
        "def display_image_as_blocks(image_data):\n",
        "    # Reshape the 784-element array back to 28x28\n",
        "    image_2d = image_data.reshape(28, 28)\n",
        "\n",
        "    print(\"\\nBlock Graphic of First Training Image:\")\n",
        "    for row in image_2d:\n",
        "        for pixel in row:\n",
        "            # Map pixel intensity to characters for a block graphic\n",
        "            if pixel < 0.2:\n",
        "                print('  ', end='') # empty space\n",
        "            elif pixel < 0.4:\n",
        "                print(' .', end='') # light gray\n",
        "            elif pixel < 0.6:\n",
        "                print(' -', end='') # medium gray\n",
        "            elif pixel < 0.8:\n",
        "                print(' +', end='') # darker gray\n",
        "            else:\n",
        "                print(' #', end='') # black\n",
        "        print() # New line after each row\n",
        "\n",
        "display_image_as_blocks(x_train[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Block Graphic of First Training Image:\n",
            "                                                        \n",
            "                                                        \n",
            "                                                        \n",
            "                                                        \n",
            "                                                        \n",
            "                                 - - +   + # # -        \n",
            "                     . + + # # # # # # + # # + .        \n",
            "                 # # # # # # # # # # . . . .            \n",
            "                 # # # # # # + + # #                    \n",
            "                 . + - # # #       +                    \n",
            "                       + # .                            \n",
            "                       - # +                            \n",
            "                         + # .                          \n",
            "                           # # + -                      \n",
            "                           . # # # -                    \n",
            "                               + # # -                  \n",
            "                                 . # # +                \n",
            "                                   # # # .              \n",
            "                               - + # # #                \n",
            "                           - # # # # # +                \n",
            "                       - # # # # # + .                  \n",
            "                   . # # # # # + .                      \n",
            "               + # # # # # + .                          \n",
            "         . + # # # # # # -                              \n",
            "         - # # # # - -                                  \n",
            "                                                        \n",
            "                                                        \n",
            "                                                        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4ee7aab"
      },
      "source": [
        "# neural network\n",
        "network = [\n",
        "    Dense(28 * 28, 40),\n",
        "    Tanh(),\n",
        "    Dense(40, 10),\n",
        "    Tanh()\n",
        "]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d481d489",
        "outputId": "41c14ab4-ac06-470b-d58e-878bff942218"
      },
      "source": [
        "# train\n",
        "train(network, mse, mse_prime, x_train, y_train, epochs=100, learning_rate=0.1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/100, error=0.9024770099808573\n",
            "2/100, error=0.8262126475986363\n",
            "3/100, error=0.7850334023108451\n",
            "4/100, error=0.7391199405179384\n",
            "5/100, error=0.6906683098607453\n",
            "6/100, error=0.6255189888280787\n",
            "7/100, error=0.5314980494312231\n",
            "8/100, error=0.3863777159875171\n",
            "9/100, error=0.2621246788599441\n",
            "10/100, error=0.19274811326990185\n",
            "11/100, error=0.16304463474031775\n",
            "12/100, error=0.14239054611186322\n",
            "13/100, error=0.1278825933879086\n",
            "14/100, error=0.1211418487852767\n",
            "15/100, error=0.11677072935063414\n",
            "16/100, error=0.11359899795308467\n",
            "17/100, error=0.11092315295603612\n",
            "18/100, error=0.10836110910413849\n",
            "19/100, error=0.10610502283485176\n",
            "20/100, error=0.10423113880719938\n",
            "21/100, error=0.10282540994724966\n",
            "22/100, error=0.10140188168205277\n",
            "23/100, error=0.09974575423425276\n",
            "24/100, error=0.09781691363572977\n",
            "25/100, error=0.09600906348316172\n",
            "26/100, error=0.09448801555184114\n",
            "27/100, error=0.09336445968270746\n",
            "28/100, error=0.09235204144647048\n",
            "29/100, error=0.09134826220314723\n",
            "30/100, error=0.0904132160742479\n",
            "31/100, error=0.08945460356167385\n",
            "32/100, error=0.08841793279529049\n",
            "33/100, error=0.08749315534453832\n",
            "34/100, error=0.08668552700078495\n",
            "35/100, error=0.08595708351313482\n",
            "36/100, error=0.08522378422195187\n",
            "37/100, error=0.08456741930581765\n",
            "38/100, error=0.08384964191292764\n",
            "39/100, error=0.0829422876204927\n",
            "40/100, error=0.08200027200231676\n",
            "41/100, error=0.08124447114845337\n",
            "42/100, error=0.0805706739139231\n",
            "43/100, error=0.07997720396066783\n",
            "44/100, error=0.07940668870858422\n",
            "45/100, error=0.07883180448406901\n",
            "46/100, error=0.07824972659586157\n",
            "47/100, error=0.07772401246981767\n",
            "48/100, error=0.07704585244871863\n",
            "49/100, error=0.07658451629836315\n",
            "50/100, error=0.07607081145824494\n",
            "51/100, error=0.07566816556976778\n",
            "52/100, error=0.07523746230896203\n",
            "53/100, error=0.07485090297171176\n",
            "54/100, error=0.0743733288618197\n",
            "55/100, error=0.07392430554083058\n",
            "56/100, error=0.07339792857962024\n",
            "57/100, error=0.07292173453076535\n",
            "58/100, error=0.0723800150476503\n",
            "59/100, error=0.07194106799860735\n",
            "60/100, error=0.07151217392064237\n",
            "61/100, error=0.07097427884327534\n",
            "62/100, error=0.07060291463193076\n",
            "63/100, error=0.07025662193720798\n",
            "64/100, error=0.06986219993623116\n",
            "65/100, error=0.06953471500333233\n",
            "66/100, error=0.06921704250623635\n",
            "67/100, error=0.06883461069805441\n",
            "68/100, error=0.0685077904534939\n",
            "69/100, error=0.06823810116305838\n",
            "70/100, error=0.0679073985472437\n",
            "71/100, error=0.06761541366113571\n",
            "72/100, error=0.06733750093680178\n",
            "73/100, error=0.06697937572767086\n",
            "74/100, error=0.0666726785011795\n",
            "75/100, error=0.06640391452399914\n",
            "76/100, error=0.06609513786142857\n",
            "77/100, error=0.06582225182605027\n",
            "78/100, error=0.06553396574131737\n",
            "79/100, error=0.06527048737924733\n",
            "80/100, error=0.06490466938833253\n",
            "81/100, error=0.0644645252375668\n",
            "82/100, error=0.06407166897999408\n",
            "83/100, error=0.06371406470339998\n",
            "84/100, error=0.06323681090995267\n",
            "85/100, error=0.0626556413267317\n",
            "86/100, error=0.06233730529111243\n",
            "87/100, error=0.06207445611845389\n",
            "88/100, error=0.06182647540085906\n",
            "89/100, error=0.06159130546354519\n",
            "90/100, error=0.06135343260084912\n",
            "91/100, error=0.061149144940800364\n",
            "92/100, error=0.06094116053835125\n",
            "93/100, error=0.060733990413740085\n",
            "94/100, error=0.060474121695623655\n",
            "95/100, error=0.06024486256669599\n",
            "96/100, error=0.06004866024180878\n",
            "97/100, error=0.059891237986101645\n",
            "98/100, error=0.05973206148953578\n",
            "99/100, error=0.05958634609410637\n",
            "100/100, error=0.059423522723743384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "040bcf59",
        "outputId": "a3d1e8ed-1d16-4d5e-b5ef-9824b12db4b6"
      },
      "source": [
        "# test\n",
        "for x, y in zip(x_test, y_test):\n",
        "    output = predict(network, x)\n",
        "    print('pred:', np.argmax(output), '\\ttrue:', np.argmax(y))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred: 7 \ttrue: 7\n",
            "pred: 1 \ttrue: 2\n",
            "pred: 1 \ttrue: 1\n",
            "pred: 0 \ttrue: 0\n",
            "pred: 4 \ttrue: 4\n",
            "pred: 1 \ttrue: 1\n",
            "pred: 9 \ttrue: 4\n",
            "pred: 3 \ttrue: 9\n",
            "pred: 4 \ttrue: 5\n",
            "pred: 7 \ttrue: 9\n",
            "pred: 0 \ttrue: 0\n",
            "pred: 3 \ttrue: 6\n",
            "pred: 9 \ttrue: 9\n",
            "pred: 0 \ttrue: 0\n",
            "pred: 1 \ttrue: 1\n",
            "pred: 9 \ttrue: 5\n",
            "pred: 9 \ttrue: 9\n",
            "pred: 7 \ttrue: 7\n",
            "pred: 3 \ttrue: 3\n",
            "pred: 9 \ttrue: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e24338c1",
        "outputId": "b58e6e01-d183-4779-e196-13520fc2c07a"
      },
      "source": [
        "correct_predictions = 0\n",
        "total_test_samples = len(x_test)\n",
        "\n",
        "for x, y in zip(x_test, y_test):\n",
        "    output = predict(network, x)\n",
        "    predicted_digit = np.argmax(output)\n",
        "    true_digit = np.argmax(y)\n",
        "\n",
        "    if predicted_digit == true_digit:\n",
        "        correct_predictions += 1\n",
        "\n",
        "accuracy = correct_predictions / total_test_samples\n",
        "print(f'Overall accuracy on the test set: {accuracy * 100:.2f}%')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall accuracy on the test set: 60.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "535f7b4c",
        "outputId": "0b3e3972-5773-44ee-e09d-13d22b961e95"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')\n",
        "    plt.title(f\"True: {np.argmax(y_test[i])}\")\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}